{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a9755e5",
   "metadata": {},
   "source": [
    "# Data collection and cleaning: ukb669914"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "instant-relationship",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the json module, which allows us to work with JSON files in Python.\n",
    "import json\n",
    "with open('/Users/marinacamacho/Desktop/Master_I/var.json') as f:\n",
    "    var_temp = json.load(f)\n",
    "\n",
    "# Import the numpy module. Numpy is a library in Python that provides support for large, \n",
    "# multi-dimensional arrays and matrices, along with a large collection of high-level \n",
    "# mathematical functions to operate on these arrays.\n",
    "import numpy as np\n",
    "\n",
    "# Import the pandas module, which allows us to work with data structures and data analysis tools.\n",
    "# Given it's a large dataset, the 'nrows=1' argument is used to read only the first row of the CSV file.\n",
    "import pandas as pd\n",
    "df_ = pd.read_csv('/Users/marinacamacho/Desktop/Master_I/Raw_Data/ukb669914.csv', nrows=1)  # Read only the first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a552508c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdc1c4af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eid</th>\n",
       "      <th>50-0.0</th>\n",
       "      <th>50-1.0</th>\n",
       "      <th>50-2.0</th>\n",
       "      <th>50-3.0</th>\n",
       "      <th>74-0.0</th>\n",
       "      <th>74-1.0</th>\n",
       "      <th>74-2.0</th>\n",
       "      <th>74-3.0</th>\n",
       "      <th>84-0.0</th>\n",
       "      <th>...</th>\n",
       "      <th>130936-0.0</th>\n",
       "      <th>130938-0.0</th>\n",
       "      <th>130940-0.0</th>\n",
       "      <th>130942-0.0</th>\n",
       "      <th>130944-0.0</th>\n",
       "      <th>130946-0.0</th>\n",
       "      <th>130948-0.0</th>\n",
       "      <th>130950-0.0</th>\n",
       "      <th>130952-0.0</th>\n",
       "      <th>130954-0.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000010</td>\n",
       "      <td>169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 604 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       eid  50-0.0  50-1.0  50-2.0  50-3.0  74-0.0  74-1.0  74-2.0  74-3.0  \\\n",
       "0  1000010     169     NaN     NaN     NaN       4     NaN     NaN     NaN   \n",
       "\n",
       "   84-0.0  ...  130936-0.0  130938-0.0  130940-0.0  130942-0.0  130944-0.0  \\\n",
       "0    2008  ...         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "   130946-0.0  130948-0.0  130950-0.0  130952-0.0  130954-0.0  \n",
       "0         NaN         NaN         NaN         NaN         NaN  \n",
       "\n",
       "[1 rows x 604 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdb7c32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_including_minus_0 = df_.filter(regex='.*-1.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f738fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7ea5fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables that we don't have a second assesment, hence cannot be traced\n",
    "not_treaceable = ['20122-1.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a228b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary named var_temp. The keys are original variable names and the values are the new names that we want to assign to them.\n",
    "# The general structure is 'original_name' : 'new_name'. This dictionary is used for renaming variables from the original dataset,\n",
    "# making the variable names more understandable and easier to work with.\n",
    "# This dictionary will contain general external exposures.\n",
    "var_temp = {'eid': 'f.eid',\n",
    " '50-1.0' : 'Standing_height',\n",
    " '74-1.0': 'Fasting_time',\n",
    " '84-1.0': 'Cancer_age_0.0',\n",
    " '84-1.1': 'Cancer_age_0.1',\n",
    " '84-1.2': 'Cancer_age_0.2',\n",
    " '84-1.3': 'Cancer_age_0.3',\n",
    " '84-1.4': 'Cancer_age_0.4',\n",
    " '84-1.5': 'Cancer_age_0.5',\n",
    " '134-1.0': 'Number_cancers',\n",
    " '136-1.0': 'Number_operation',\n",
    " '806-1.0': 'Job_walking_standing',\n",
    " '816-1.0': 'Job_heavy_manual',\n",
    " '826-1.0': 'Job_involves_shift',\n",
    " '1031-1.0': 'Frequency_friend_family_visits',\n",
    " '1050-1.0': 'Time_outdoors_summer',\n",
    " '1060-1.0': 'Time_outdoors_winter',\n",
    " '1110-1.0': 'Length_phone_use',\n",
    " '1120-1.0': 'Weekly_phone_use',\n",
    " '1140-1.0': 'Difference_phone_use',\n",
    " '1170-1.0': 'Getting_up_in_morning',\n",
    " '1180-1.0': 'Morning_evening_person',\n",
    " '1210-1.0': 'Snoring',\n",
    " '1498-1.0': 'Coffee_intake',\n",
    " '1717-1.0': 'Skin_colour',\n",
    " '1920-1.0': 'Mood_swings',\n",
    " '1930-1.0': 'Miserableness',\n",
    " '1940-1.0': 'Irritability',\n",
    " '1950-1.0': 'Sensitivity',\n",
    " '1960-1.0': 'Fed-up_feelings',\n",
    " '1970-1.0': 'Nervous_feelings',\n",
    " '1980-1.0': 'Worrier/Anxious_feelings',\n",
    " '1990-1.0': 'Tense',\n",
    " '2000-1.0': 'Worry_too_long_after_embarrassment',\n",
    " '2010-1.0': 'Suffer_from_nerves',\n",
    " '2020-1.0': 'Loneliness_isolation',\n",
    " '2030-1.0': 'Guilty_feelings',\n",
    " '2040-1.0': 'Risk_taking',\n",
    " '2110-1.0': 'Able_to_confide',\n",
    " '2178-1.0': 'Overall_health_rating',\n",
    " '2237-1.0': 'Plays_computer_games',\n",
    " '2247-1.0': 'Hearing_difficulty/problems',\n",
    " '2267-1.0': 'Use_of_sun/uv_protection',\n",
    " '2277-1.0': 'Frequency_of_solarium/sunlamp',\n",
    " '2415-1.0': 'Had_major_operation',\n",
    " '2453-1.0': 'Cancer_diagnosed_by_doctor',\n",
    " '2463-1.0': 'Fractured/broken_bones',\n",
    " '2473-1.0': 'Other_serious_condition',\n",
    " '2844-1.0': 'Had_other_major_operations',\n",
    " '4526-1.0': 'Happiness',\n",
    " '4537-1.0': 'Work/job_satisfaction',\n",
    " '4548-1.0': 'Health_satisfaction',\n",
    " '4559-1.0': 'Family_relationship satisfaction',\n",
    " '4570-1.0': 'Friendships_satisfaction',\n",
    " '4581-1.0': 'Financial_satisfaction',\n",
    " '4642-1.0': 'Ever_manic/hyper',\n",
    " '4653-1.0': 'Ever_highly_irritable/argumentative',\n",
    " '4728-1.0': 'Leg_pain_on_walking',\n",
    " '4803-1.0': 'Tinnitus',\n",
    " '5663-1.0': 'Length_manic/irritable_episode',\n",
    " '5674-1.0': 'Severity_of_manic/irritable_episodes',\n",
    " '6149-1.0': 'Mouth/teeth_problems_0',\n",
    " '6149-1.1': 'Mouth/teeth_problems_1',\n",
    " '6149-1.2': 'Mouth/teeth_problems_2',\n",
    " '6149-1.3': 'Mouth/teeth_problems_3',\n",
    " '6149-1.4': 'Mouth/teeth_problems_4',\n",
    " '6149-1.5': 'Mouth/teeth_problems_5',\n",
    " '6156-1.0': 'Manic/hyper_symptoms_0',\n",
    " '6156-1.1': 'Manic/hyper_symptoms_1',\n",
    " '6156-1.2': 'Manic/hyper_symptoms_2',\n",
    " '6156-1.3': 'Manic/hyper_symptoms_3',\n",
    " '6159-1.0': 'Pain_type_0',\n",
    " '6159-1.1': 'Pain_type_1',\n",
    " '6159-1.2': 'Pain_type_2',\n",
    " '6159-1.3': 'Pain_type_3',\n",
    " '6159-1.4': 'Pain_type_4',\n",
    " '6159-1.5': 'Pain_type_5',\n",
    " '6159-1.6': 'Pain_type_6',\n",
    " '6160-1.0': 'Leisure/social_activities_0',\n",
    " '6160-1.1': 'Leisure/social_activities_1',\n",
    " '6160-1.2': 'Leisure/social_activities_2',\n",
    " '6160-1.3': 'Leisure/social_activities_3',\n",
    " '6160-1.4': 'Leisure/social_activities_4',\n",
    " '20023-1.0': 'Mean_time_to_identify_matches',\n",
    " '20107-1.0': 'Illnesses_father_0',\n",
    " '20107-1.1': 'Illnesses_father_1',\n",
    " '20107-1.2': 'Illnesses_father_2',\n",
    " '20107-1.3': 'Illnesses_father_3',\n",
    " '20107-1.4': 'Illnesses_father_4',\n",
    " '20107-1.5': 'Illnesses_father_5',\n",
    " '20107-1.6': 'Illnesses_father_6',\n",
    " '20107-1.7': 'Illnesses_father_7',\n",
    " '20107-1.8': 'Illnesses_father_8',\n",
    " '20107-1.9': 'Illnesses_father_9',\n",
    " '20110-1.0': 'Illnesses_mother_0',\n",
    " '20110-1.1': 'Illnesses_mother_1',\n",
    " '20110-1.2': 'Illnesses_mother_2',\n",
    " '20110-1.3': 'Illnesses_mother_3',\n",
    " '20110-1.4': 'Illnesses_mother_4',\n",
    " '20110-1.5': 'Illnesses_mother_5',\n",
    " '20110-1.6': 'Illnesses_mother_6',\n",
    " '20110-1.7': 'Illnesses_mother_7',\n",
    " '20110-1.8': 'Illnesses_mother_8',\n",
    " '20110-1.9': 'Illnesses_mother_9',\n",
    " '20110-1.10': 'Illnesses_mother_10',\n",
    " '20111-1.0': 'Illnesses_siblings_0',\n",
    " '20111-1.1': 'Illnesses_siblings_1',\n",
    " '20111-1.2': 'Illnesses_siblings_2',\n",
    " '20111-1.3': 'Illnesses_siblings_3',\n",
    " '20111-1.4': 'Illnesses_siblings_4',\n",
    " '20111-1.5': 'Illnesses_siblings_5',\n",
    " '20111-1.6': 'Illnesses_siblings_6',\n",
    " '20111-1.7': 'Illnesses_siblings_7',\n",
    " '20111-1.8': 'Illnesses_siblings_8',\n",
    " '20111-1.9': 'Illnesses_siblings_9',\n",
    " '20111-1.10': 'Illnesses_siblings_10',\n",
    " '20111-1.11': 'Illnesses_siblings_11',\n",
    " '20122-0.0': 'Bipolar_disorder_status',\n",
    " '21002-1.0': 'Weight'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fe5fe74",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Download all the data (not just the columns names) with the new variable names. \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_ \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/marinacamacho/Desktop/Master_I/Raw_Data/ukb669914.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvar_temp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df_ \u001b[38;5;241m=\u001b[39m df_\u001b[38;5;241m.\u001b[39mrename(columns \u001b[38;5;241m=\u001b[39m var_temp )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:586\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    571\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    572\u001b[0m     dialect,\n\u001b[1;32m    573\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    583\u001b[0m )\n\u001b[1;32m    584\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:488\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1047\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, nrows\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1046\u001b[0m     nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m-> 1047\u001b[0m     index, columns, col_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1049\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m col_dict:\n\u001b[1;32m   1051\u001b[0m             \u001b[38;5;66;03m# Any column is actually fine:\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py:223\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 223\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    225\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:801\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:880\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:1039\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/dtypes/common.py:1420\u001b[0m, in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1413\u001b[0m     \u001b[38;5;66;03m# Note: if other EA dtypes are ever held in HybridBlock, exclude those\u001b[39;00m\n\u001b[1;32m   1414\u001b[0m     \u001b[38;5;66;03m#  here too.\u001b[39;00m\n\u001b[1;32m   1415\u001b[0m     \u001b[38;5;66;03m# NB: need to check DatetimeTZDtype and not is_datetime64tz_dtype\u001b[39;00m\n\u001b[1;32m   1416\u001b[0m     \u001b[38;5;66;03m#  to exclude ArrowTimestampUSDtype\u001b[39;00m\n\u001b[1;32m   1417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, DatetimeTZDtype)\n\u001b[0;32m-> 1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_extension_array_dtype\u001b[39m(arr_or_dtype) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;124;03m    Check if an object is a pandas extension array type.\u001b[39;00m\n\u001b[1;32m   1423\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1465\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(arr_or_dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, arr_or_dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Download all the data (not just the columns names) with the new variable names. \n",
    "df_ = pd.read_csv('/Users/marinacamacho/Desktop/Master_I/Raw_Data/ukb669914.csv', usecols = var_temp.keys())\n",
    "df_ = df_.rename(columns = var_temp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dc2cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'Cancer_age_first' in the dataframe df_. \n",
    "# This column is created by applying a lambda function across the dataframe rows (axis=1) \n",
    "# which takes the minimum value among the 'Cancer_age_0.0', 'Cancer_age_0.1', ..., 'Cancer_age_0.5' columns for each row.\n",
    "df_['Cancer_age_first'] = df_.apply(lambda row: min(row['Cancer_age_0.0'], row['Cancer_age_0.1'], row['Cancer_age_0.2'], row['Cancer_age_0.3'], row['Cancer_age_0.4'], row['Cancer_age_0.5']), axis=1)\n",
    "del df_['Cancer_age_0.0']\n",
    "del df_['Cancer_age_0.1']\n",
    "del df_['Cancer_age_0.2']\n",
    "del df_['Cancer_age_0.3']\n",
    "del df_['Cancer_age_0.4']\n",
    "del df_['Cancer_age_0.5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b673e2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary to map the code to its corresponding meaning\n",
    "code_meaning = {\n",
    "    1: 'Mouth_ulcers',\n",
    "    2: 'Painful_gums',\n",
    "    3: 'Bleeding_gums',\n",
    "    4: 'Loose_teeth',\n",
    "    5: 'Toothache',\n",
    "    6: 'Dentures',\n",
    "    -7: 'None_of_the_above',\n",
    "    -3: 'Prefer_not_to_answer'\n",
    "}\n",
    "\n",
    "# Specify the column names you want to extract\n",
    "columns_to_extract = ['Mouth/teeth_problems_0', 'Mouth/teeth_problems_1', 'Mouth/teeth_problems_2',\n",
    "                      'Mouth/teeth_problems_3', 'Mouth/teeth_problems_4', 'Mouth/teeth_problems_5']\n",
    "\n",
    "# Create a new dataframe with only the extracted columns\n",
    "extracted_df = df_[columns_to_extract].copy()\n",
    "\n",
    "# Create a new dataframe to store the results\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over each code and meaning in the dictionary\n",
    "for code, meaning in code_meaning.items():\n",
    "    # Check if the code is positive or negative\n",
    "    is_positive = code > 0\n",
    "\n",
    "    # Create a boolean mask indicating where the code is present in the extracted columns\n",
    "    code_mask = extracted_df.isin([code])\n",
    "\n",
    "    # Count the occurrences of the code in each row\n",
    "    code_counts = code_mask.sum(axis=1)\n",
    "\n",
    "    # Create a new column with the meaning and initialize it as 1 if the code is present, else 0\n",
    "    result_df[meaning] = np.where(code_counts > 0, 1, np.nan)\n",
    "\n",
    "# Concatenate the result dataframe with the original dataframe\n",
    "df_ = pd.concat([df_, result_df], axis=1)\n",
    "\n",
    "df_['Mouth_ulcers'] = np.where(df_['None_of_the_above'] == 1, 0, df_['Mouth_ulcers'])\n",
    "df_['Painful_gums'] = np.where(df_['None_of_the_above'] == 1, 0, df_['Painful_gums'])\n",
    "df_['Bleeding_gums'] = np.where(df_['None_of_the_above'] == 1, 0, df_['Bleeding_gums'])\n",
    "df_['Loose_teeth'] = np.where(df_['None_of_the_above'] == 1, 0, df_['Loose_teeth'])\n",
    "df_['Toothache'] = np.where(df_['None_of_the_above'] == 1, 0, df_['Toothache'])\n",
    "df_['Dentures'] = np.where(df_['None_of_the_above'] == 1, 0, df_['Dentures'])\n",
    "\n",
    "del df_['Mouth/teeth_problems_0']\n",
    "del df_['Mouth/teeth_problems_1']\n",
    "del df_['Mouth/teeth_problems_2']\n",
    "del df_['Mouth/teeth_problems_3']\n",
    "del df_['Mouth/teeth_problems_4']\n",
    "del df_['Mouth/teeth_problems_5']\n",
    "\n",
    "del df_['None_of_the_above']\n",
    "del df_['Prefer_not_to_answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf28664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your dataframe is named 'df' with the renamed columns\n",
    "# Creating a dictionary to map the code to its corresponding meaning\n",
    "code_meaning = {\n",
    "    11: 'Active_than_usual',\n",
    "    12: 'Talkative_than_usual',\n",
    "    13: 'Needed_less_sleep_than_usual',\n",
    "    14: 'Creative_than_usual',\n",
    "    15: 'All_of_the_above',\n",
    "    -7: 'None_of_the_above',\n",
    "}\n",
    "\n",
    "# Specify the column names you want to extract\n",
    "columns_to_extract = ['Manic/hyper_symptoms_0', 'Manic/hyper_symptoms_1', 'Manic/hyper_symptoms_2',\n",
    "                      'Manic/hyper_symptoms_3']\n",
    "\n",
    "# Create a new dataframe with only the extracted columns\n",
    "extracted_df = df_[columns_to_extract].copy()\n",
    "\n",
    "# Create a new dataframe to store the results\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over each code and meaning in the dictionary\n",
    "for code, meaning in code_meaning.items():\n",
    "    # Check if the code is positive or negative\n",
    "    is_positive = code > 0\n",
    "\n",
    "    # Create a boolean mask indicating where the code is present in the extracted columns\n",
    "    code_mask = extracted_df.isin([code])\n",
    "\n",
    "    # Count the occurrences of the code in each row\n",
    "    code_counts = code_mask.sum(axis=1)\n",
    "\n",
    "    # Create a new column with the meaning and initialize it as 1 if the code is present, else 0\n",
    "    result_df[meaning] = np.where(code_counts > 0, 1, np.nan)\n",
    "\n",
    "# Concatenate the result dataframe with the original dataframe\n",
    "df_ = pd.concat([df_, result_df], axis=1)\n",
    "\n",
    "df_['Active_than_usual'] = np.where(df_['None_of_the_above'] == 1, 0, df_['Active_than_usual'])\n",
    "df_['Talkative_than_usual'] = np.where(df_['None_of_the_above'] == 1, 0, df_['Talkative_than_usual'])\n",
    "df_['Needed_less_sleep_than_usual'] = np.where(df_['None_of_the_above'] == 1, 0, df_['Needed_less_sleep_than_usual'])\n",
    "df_['Creative_than_usual'] = np.where(df_['None_of_the_above'] == 1, 0, df_['Creative_than_usual'])\n",
    "\n",
    "df_['Active_than_usual'] = np.where(df_['All_of_the_above'] == 1, 1, df_['Active_than_usual'])\n",
    "df_['Talkative_than_usual'] = np.where(df_['All_of_the_above'] == 1, 1, df_['Talkative_than_usual'])\n",
    "df_['Needed_less_sleep_than_usual'] = np.where(df_['All_of_the_above'] == 1, 1, df_['Needed_less_sleep_than_usual'])\n",
    "df_['Creative_than_usual'] = np.where(df_['All_of_the_above'] == 1, 1, df_['Creative_than_usual'])\n",
    "\n",
    "del df_['Manic/hyper_symptoms_0']\n",
    "del df_['Manic/hyper_symptoms_1']\n",
    "del df_['Manic/hyper_symptoms_2']\n",
    "del df_['Manic/hyper_symptoms_3']\n",
    "\n",
    "del df_['None_of_the_above']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36facaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your dataframe is named 'df' with the renamed columns\n",
    "# Creating a dictionary to map the code to its corresponding meaning\n",
    "code_meaning = {\n",
    "1:'Headache',\n",
    "2:'Facial_pain',\n",
    "3:'Neck_shoulder_pain',\n",
    "4:'Back_pain',\n",
    "5:'Stomach_abdominal_pain',\n",
    "6:'Hip_pain',\n",
    "7:'Knee_pain',\n",
    "8:'Pain_body',\n",
    "-7:'None_of_the_above',\n",
    "-3:'Prefer_not_to_answer'\n",
    "}\n",
    "\n",
    "# Specify the column names you want to extract\n",
    "columns_to_extract = ['Pain_type_0', 'Pain_type_1', 'Pain_type_2',\n",
    "                      'Pain_type_3', 'Pain_type_4', 'Pain_type_5',\n",
    "                     'Pain_type_6']\n",
    "\n",
    "# Create a new dataframe with only the extracted columns\n",
    "extracted_df = df_[columns_to_extract].copy()\n",
    "\n",
    "# Create a new dataframe to store the results\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over each code and meaning in the dictionary\n",
    "for code, meaning in code_meaning.items():\n",
    "    # Check if the code is positive or negative\n",
    "    is_positive = code > 0\n",
    "\n",
    "    # Create a boolean mask indicating where the code is present in the extracted columns\n",
    "    code_mask = extracted_df.isin([code])\n",
    "\n",
    "    # Count the occurrences of the code in each row\n",
    "    code_counts = code_mask.sum(axis=1)\n",
    "\n",
    "    # Create a new column with the meaning and initialize it as 1 if the code is present, else 0\n",
    "    result_df[meaning] = np.where(code_counts > 0, 1, np.nan)\n",
    "\n",
    "# Concatenate the result dataframe with the original dataframe\n",
    "df_ = pd.concat([df_, result_df], axis=1)\n",
    "\n",
    "df_['Headache'] = np.where(df_['None_of_the_above'] == 1, 0, df_['Headache'])\n",
    "df_['Facial_pain'] = np.where(df_['None_of_the_above'] == 1, 0, df_['Facial_pain'])\n",
    "df_['Neck_shoulder_pain'] = np.where(df_['None_of_the_above'] == 1, 0, df_['Neck_shoulder_pain'])\n",
    "df_['Back_pain'] = np.where(df_['None_of_the_above'] == 1, 0, df_['Back_pain'])\n",
    "df_['Stomach_abdominal_pain'] = np.where(df_['None_of_the_above'] == 1, 0, df_['Stomach_abdominal_pain'])\n",
    "df_['Hip_pain'] = np.where(df_['None_of_the_above'] == 1, 0, df_['Hip_pain'])\n",
    "df_['Knee_pain'] = np.where(df_['None_of_the_above'] == 1, 0, df_['Knee_pain'])\n",
    "df_['Pain_body'] = np.where(df_['None_of_the_above'] == 1, 0, df_['Pain_body'])\n",
    "\n",
    "del df_['Pain_type_0']\n",
    "del df_['Pain_type_1']\n",
    "del df_['Pain_type_2']\n",
    "del df_['Pain_type_3']\n",
    "del df_['Pain_type_4']\n",
    "del df_['Pain_type_5']\n",
    "del df_['Pain_type_6']\n",
    "\n",
    "del df_['None_of_the_above']\n",
    "del df_['Prefer_not_to_answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76abe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your dataframe is named 'df' with the renamed columns\n",
    "# Creating a dictionary to map the code to its corresponding meaning\n",
    "code_meaning = {\n",
    "1:'Sports_club_or_gym',\n",
    "2:'Pub_or_social_club',\n",
    "3:'Religious_group',\n",
    "4:'Adult_education_class',\n",
    "5:'Other_group_activity',\n",
    "-7:'None_of_the_above',\n",
    "-3:'Prefer_not_to_answer'\n",
    "}\n",
    "\n",
    "# Specify the column names you want to extract\n",
    "columns_to_extract = ['Leisure/social_activities_0', 'Leisure/social_activities_1', 'Leisure/social_activities_2',\n",
    "                      'Leisure/social_activities_3', 'Leisure/social_activities_4']\n",
    "\n",
    "# Create a new dataframe with only the extracted columns\n",
    "extracted_df = df_[columns_to_extract].copy()\n",
    "\n",
    "# Create a new dataframe to store the results\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over each code and meaning in the dictionary\n",
    "for code, meaning in code_meaning.items():\n",
    "    # Check if the code is positive or negative\n",
    "    is_positive = code > 0\n",
    "\n",
    "    # Create a boolean mask indicating where the code is present in the extracted columns\n",
    "    code_mask = extracted_df.isin([code])\n",
    "\n",
    "    # Count the occurrences of the code in each row\n",
    "    code_counts = code_mask.sum(axis=1)\n",
    "\n",
    "    # Create a new column with the meaning and initialize it as 1 if the code is present, else 0\n",
    "    result_df[meaning] = np.where(code_counts > 0, 1, np.nan)\n",
    "\n",
    "# Concatenate the result dataframe with the original dataframe\n",
    "df_ = pd.concat([df_, result_df], axis=1)\n",
    "\n",
    "df_['Sports_club_or_gym'] = np.where(df_['None_of_the_above'] == 1, 0, df_['Sports_club_or_gym'])\n",
    "df_['Pub_or_social_club'] = np.where(df_['None_of_the_above'] == 1, 0, df_['Pub_or_social_club'])\n",
    "df_['Religious_group'] = np.where(df_['None_of_the_above'] == 1, 0, df_['Religious_group'])\n",
    "df_['Adult_education_class'] = np.where(df_['None_of_the_above'] == 1, 0, df_['Adult_education_class'])\n",
    "df_['Other_group_activity'] = np.where(df_['None_of_the_above'] == 1, 0, df_['Other_group_activity'])\n",
    "\n",
    "del df_['Leisure/social_activities_0']\n",
    "del df_['Leisure/social_activities_1']\n",
    "del df_['Leisure/social_activities_2']\n",
    "del df_['Leisure/social_activities_3']\n",
    "del df_['Leisure/social_activities_4']\n",
    "\n",
    "del df_['None_of_the_above']\n",
    "del df_['Prefer_not_to_answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2672711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your dataframe is named 'df' with the renamed columns\n",
    "# Creating a dictionary to map the code to its corresponding meaning\n",
    "code_meaning = {\n",
    "14:'Hip_fracture_F',\n",
    "13:'Prostate_cancer_F',\n",
    "12:'Severe_depression_F',\n",
    "11:'Parkinson_disease_F',\n",
    "10:'Alzheimer_disease/dementia_F',\n",
    "9:'Diabetes_F',\n",
    "8:'High_blood_pressure_F',\n",
    "6:'Chronic_bronchitis/emphysema_F',\n",
    "5:'Breast_cancer_F',\n",
    "4:'Bowel_cancer_F',\n",
    "3:'Lung_cancer_F',\n",
    "2:'Stroke_F',\n",
    "1:'Heart_disease_F',\n",
    "-11:'Do_not_know_(group_1)_F',\n",
    "-13:'Prefer_not_to_answer_(group_1)_F',\n",
    "-17:'None_of_the_above_(group_1)_F',\n",
    "-21:'Do_not_know_(group_2)_F',\n",
    "-23:'Prefer_not_to_answer_(group_2)_F',\n",
    "-27:'None_of_the_above_(group_2)_F'\n",
    "}\n",
    "\n",
    "# Specify the column names you want to extract\n",
    "columns_to_extract = ['Illnesses_father_0', 'Illnesses_father_1', 'Illnesses_father_2',\n",
    "                      'Illnesses_father_3', 'Illnesses_father_4', 'Illnesses_father_5',\n",
    "                      'Illnesses_father_6', 'Illnesses_father_7', 'Illnesses_father_8',\n",
    "                     'Illnesses_father_9']\n",
    "\n",
    "# Create a new dataframe with only the extracted columns\n",
    "extracted_df = df_[columns_to_extract].copy()\n",
    "\n",
    "# Create a new dataframe to store the results\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over each code and meaning in the dictionary\n",
    "for code, meaning in code_meaning.items():\n",
    "    # Check if the code is positive or negative\n",
    "    is_positive = code > 0\n",
    "\n",
    "    # Create a boolean mask indicating where the code is present in the extracted columns\n",
    "    code_mask = extracted_df.isin([code])\n",
    "\n",
    "    # Count the occurrences of the code in each row\n",
    "    code_counts = code_mask.sum(axis=1)\n",
    "\n",
    "    # Create a new column with the meaning and initialize it as 1 if the code is present, else 0\n",
    "    result_df[meaning] = np.where(code_counts > 0, 1, 0)\n",
    "\n",
    "# Concatenate the result dataframe with the original dataframe\n",
    "df_ = pd.concat([df_, result_df], axis=1)\n",
    "\n",
    "df_['Hip_fracture_F'] = np.where((df_['Prefer_not_to_answer_(group_1)_F'] == 1) & (df_['Prefer_not_to_answer_(group_2)_F'] == 1), np.nan, df_['Hip_fracture_F'])\n",
    "df_['Prostate_cancer_F'] = np.where((df_['Prefer_not_to_answer_(group_1)_F'] == 1) & (df_['Prefer_not_to_answer_(group_2)_F'] == 1), np.nan, df_['Prostate_cancer_F'])\n",
    "df_['Severe_depression_F'] = np.where((df_['Prefer_not_to_answer_(group_1)_F'] == 1) & (df_['Prefer_not_to_answer_(group_2)_F'] == 1), np.nan, df_['Severe_depression_F'])\n",
    "df_['Parkinson_disease_F'] = np.where((df_['Prefer_not_to_answer_(group_1)_F'] == 1) & (df_['Prefer_not_to_answer_(group_2)_F'] == 1), np.nan, df_['Parkinson_disease_F'])\n",
    "df_['Alzheimer_disease/dementia_F'] = np.where((df_['Prefer_not_to_answer_(group_1)_F'] == 1) & (df_['Prefer_not_to_answer_(group_2)_F'] == 1), np.nan, df_['Alzheimer_disease/dementia_F'])\n",
    "df_['Diabetes_F'] = np.where((df_['Prefer_not_to_answer_(group_1)_F'] == 1) & (df_['Prefer_not_to_answer_(group_2)_F'] == 1), np.nan, df_['Diabetes_F'])\n",
    "df_['High_blood_pressure_F'] = np.where((df_['Prefer_not_to_answer_(group_1)_F'] == 1) & (df_['Prefer_not_to_answer_(group_2)_F'] == 1), np.nan, df_['High_blood_pressure_F'])\n",
    "df_['Chronic_bronchitis/emphysema_F'] = np.where((df_['Prefer_not_to_answer_(group_1)_F'] == 1) & (df_['Prefer_not_to_answer_(group_2)_F'] == 1), np.nan, df_['Chronic_bronchitis/emphysema_F'])\n",
    "df_['Breast_cancer_F'] = np.where((df_['Prefer_not_to_answer_(group_1)_F'] == 1) & (df_['Prefer_not_to_answer_(group_2)_F'] == 1), np.nan, df_['Breast_cancer_F'])\n",
    "df_['Bowel_cancer_F'] = np.where((df_['Prefer_not_to_answer_(group_1)_F'] == 1) & (df_['Prefer_not_to_answer_(group_2)_F'] == 1), np.nan, df_['Bowel_cancer_F'])\n",
    "df_['Lung_cancer_F'] = np.where((df_['Prefer_not_to_answer_(group_1)_F'] == 1) & (df_['Prefer_not_to_answer_(group_2)_F'] == 1), np.nan, df_['Lung_cancer_F'])\n",
    "df_['Stroke_F'] = np.where((df_['Prefer_not_to_answer_(group_1)_F'] == 1) & (df_['Prefer_not_to_answer_(group_2)_F'] == 1), np.nan, df_['Stroke_F'])\n",
    "df_['Heart_disease_F'] = np.where((df_['Prefer_not_to_answer_(group_1)_F'] == 1) & (df_['Prefer_not_to_answer_(group_2)_F'] == 1), np.nan, df_['Heart_disease_F'])\n",
    "\n",
    "df_['Hip_fracture_F'] = np.where((df_['Do_not_know_(group_1)_F'] == 1) & (df_['Do_not_know_(group_2)_F'] == 1), np.nan, df_['Hip_fracture_F'])\n",
    "df_['Prostate_cancer_F'] = np.where((df_['Do_not_know_(group_1)_F'] == 1) & (df_['Do_not_know_(group_2)_F'] == 1), np.nan, df_['Prostate_cancer_F'])\n",
    "df_['Severe_depression_F'] = np.where((df_['Do_not_know_(group_1)_F'] == 1) & (df_['Do_not_know_(group_2)_F'] == 1), np.nan, df_['Severe_depression_F'])\n",
    "df_['Parkinson_disease_F'] = np.where((df_['Do_not_know_(group_1)_F'] == 1) & (df_['Do_not_know_(group_2)_F'] == 1), np.nan, df_['Parkinson_disease_F'])\n",
    "df_['Alzheimer_disease/dementia_F'] = np.where((df_['Do_not_know_(group_1)_F'] == 1) & (df_['Do_not_know_(group_2)_F'] == 1), np.nan, df_['Alzheimer_disease/dementia_F'])\n",
    "df_['Diabetes_F'] = np.where((df_['Do_not_know_(group_1)_F'] == 1) & (df_['Do_not_know_(group_2)_F'] == 1), np.nan, df_['Diabetes_F'])\n",
    "df_['High_blood_pressure_F'] = np.where((df_['Do_not_know_(group_1)_F'] == 1) & (df_['Do_not_know_(group_2)_F'] == 1), np.nan, df_['High_blood_pressure_F'])\n",
    "df_['Chronic_bronchitis/emphysema_F'] = np.where((df_['Do_not_know_(group_1)_F'] == 1) & (df_['Do_not_know_(group_2)_F'] == 1), np.nan, df_['Chronic_bronchitis/emphysema_F'])\n",
    "df_['Breast_cancer_F'] = np.where((df_['Do_not_know_(group_1)_F'] == 1) & (df_['Do_not_know_(group_2)_F'] == 1), np.nan, df_['Breast_cancer_F'])\n",
    "df_['Bowel_cancer_F'] = np.where((df_['Do_not_know_(group_1)_F'] == 1) & (df_['Do_not_know_(group_2)_F'] == 1), np.nan, df_['Bowel_cancer_F'])\n",
    "df_['Lung_cancer_F'] = np.where((df_['Do_not_know_(group_1)_F'] == 1) & (df_['Do_not_know_(group_2)_F'] == 1), np.nan, df_['Lung_cancer_F'])\n",
    "df_['Stroke_F'] = np.where((df_['Do_not_know_(group_1)_F'] == 1) & (df_['Do_not_know_(group_2)_F'] == 1), np.nan, df_['Stroke_F'])\n",
    "df_['Heart_disease_F'] = np.where((df_['Do_not_know_(group_1)_F'] == 1) & (df_['Do_not_know_(group_2)_F'] == 1), np.nan, df_['Heart_disease_F'])\n",
    "\n",
    "del df_['Illnesses_father_0']\n",
    "del df_['Illnesses_father_1']\n",
    "del df_['Illnesses_father_2']\n",
    "del df_['Illnesses_father_3']\n",
    "del df_['Illnesses_father_4']\n",
    "del df_['Illnesses_father_5']\n",
    "del df_['Illnesses_father_6']\n",
    "del df_['Illnesses_father_7']\n",
    "del df_['Illnesses_father_8']\n",
    "del df_['Illnesses_father_9']\n",
    "\n",
    "del df_['Do_not_know_(group_1)_F']\n",
    "del df_['Prefer_not_to_answer_(group_1)_F']\n",
    "del df_['None_of_the_above_(group_1)_F']\n",
    "del df_['Do_not_know_(group_2)_F']\n",
    "del df_['Prefer_not_to_answer_(group_2)_F']\n",
    "del df_['None_of_the_above_(group_2)_F']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3de0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your dataframe is named 'df' with the renamed columns\n",
    "# Creating a dictionary to map the code to its corresponding meaning\n",
    "code_meaning = {\n",
    "14:'Hip_fracture_M',\n",
    "13:'Prostate_cancer_M',\n",
    "12:'Severe_depression_M',\n",
    "11:'Parkinson_disease_M',\n",
    "10:'Alzheimer_disease/dementia_M',\n",
    "9:'Diabetes_M',\n",
    "8:'High_blood_pressure_M',\n",
    "6:'Chronic_bronchitis/emphysema_M',\n",
    "5:'Breast_cancer_M',\n",
    "4:'Bowel_cancer_M',\n",
    "3:'Lung_cancer_M',\n",
    "2:'Stroke_M',\n",
    "1:'Heart_disease_M',\n",
    "-11:'Do_not_know_(group_1)_M',\n",
    "-13:'Prefer_not_to_answer_(group_1)_M',\n",
    "-17:'None_of_the_above_(group_1)_M',\n",
    "-21:'Do_not_know_(group_2)_M',\n",
    "-23:'Prefer_not_to_answer_(group_2)_M',\n",
    "-27:'None_of_the_above_(group_2)_M'\n",
    "}\n",
    "\n",
    "# Specify the column names you want to extract\n",
    "columns_to_extract = ['Illnesses_mother_0', 'Illnesses_mother_1', 'Illnesses_mother_2',\n",
    "                      'Illnesses_mother_3', 'Illnesses_mother_4', 'Illnesses_mother_5',\n",
    "                      'Illnesses_mother_6', 'Illnesses_mother_7', 'Illnesses_mother_8',\n",
    "                     'Illnesses_mother_9', 'Illnesses_mother_10']\n",
    "\n",
    "# Create a new dataframe with only the extracted columns\n",
    "extracted_df = df_[columns_to_extract].copy()\n",
    "\n",
    "# Create a new dataframe to store the results\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over each code and meaning in the dictionary\n",
    "for code, meaning in code_meaning.items():\n",
    "    # Check if the code is positive or negative\n",
    "    is_positive = code > 0\n",
    "\n",
    "    # Create a boolean mask indicating where the code is present in the extracted columns\n",
    "    code_mask = extracted_df.isin([code])\n",
    "\n",
    "    # Count the occurrences of the code in each row\n",
    "    code_counts = code_mask.sum(axis=1)\n",
    "\n",
    "    # Create a new column with the meaning and initialize it as 1 if the code is present, else 0\n",
    "    result_df[meaning] = np.where(code_counts > 0, 1, 0)\n",
    "\n",
    "# Concatenate the result dataframe with the original dataframe\n",
    "df_ = pd.concat([df_, result_df], axis=1)\n",
    "\n",
    "df_['Hip_fracture_M'] = np.where((df_['Prefer_not_to_answer_(group_1)_M'] == 1) & (df_['Prefer_not_to_answer_(group_2)_M'] == 1), np.nan, df_['Hip_fracture_M'])\n",
    "df_['Prostate_cancer_M'] = np.where((df_['Prefer_not_to_answer_(group_1)_M'] == 1) & (df_['Prefer_not_to_answer_(group_2)_M'] == 1), np.nan, df_['Prostate_cancer_M'])\n",
    "df_['Severe_depression_M'] = np.where((df_['Prefer_not_to_answer_(group_1)_M'] == 1) & (df_['Prefer_not_to_answer_(group_2)_M'] == 1), np.nan, df_['Severe_depression_M'])\n",
    "df_['Parkinson_disease_M'] = np.where((df_['Prefer_not_to_answer_(group_1)_M'] == 1) & (df_['Prefer_not_to_answer_(group_2)_M'] == 1), np.nan, df_['Parkinson_disease_M'])\n",
    "df_['Alzheimer_disease/dementia_M'] = np.where((df_['Prefer_not_to_answer_(group_1)_M'] == 1) & (df_['Prefer_not_to_answer_(group_2)_M'] == 1), np.nan, df_['Alzheimer_disease/dementia_M'])\n",
    "df_['Diabetes_M'] = np.where((df_['Prefer_not_to_answer_(group_1)_M'] == 1) & (df_['Prefer_not_to_answer_(group_2)_M'] == 1), np.nan, df_['Diabetes_M'])\n",
    "df_['High_blood_pressure_M'] = np.where((df_['Prefer_not_to_answer_(group_1)_M'] == 1) & (df_['Prefer_not_to_answer_(group_2)_M'] == 1), np.nan, df_['High_blood_pressure_M'])\n",
    "df_['Chronic_bronchitis/emphysema_M'] = np.where((df_['Prefer_not_to_answer_(group_1)_M'] == 1) & (df_['Prefer_not_to_answer_(group_2)_M'] == 1), np.nan, df_['Chronic_bronchitis/emphysema_M'])\n",
    "df_['Breast_cancer_M'] = np.where((df_['Prefer_not_to_answer_(group_1)_M'] == 1) & (df_['Prefer_not_to_answer_(group_2)_M'] == 1), np.nan, df_['Breast_cancer_M'])\n",
    "df_['Bowel_cancer_M'] = np.where((df_['Prefer_not_to_answer_(group_1)_M'] == 1) & (df_['Prefer_not_to_answer_(group_2)_M'] == 1), np.nan, df_['Bowel_cancer_M'])\n",
    "df_['Lung_cancer_M'] = np.where((df_['Prefer_not_to_answer_(group_1)_M'] == 1) & (df_['Prefer_not_to_answer_(group_2)_M'] == 1), np.nan, df_['Lung_cancer_M'])\n",
    "df_['Stroke_M'] = np.where((df_['Prefer_not_to_answer_(group_1)_M'] == 1) & (df_['Prefer_not_to_answer_(group_2)_M'] == 1), np.nan, df_['Stroke_M'])\n",
    "df_['Heart_disease_M'] = np.where((df_['Prefer_not_to_answer_(group_1)_M'] == 1) & (df_['Prefer_not_to_answer_(group_2)_M'] == 1), np.nan, df_['Heart_disease_M'])\n",
    "\n",
    "df_['Hip_fracture_M'] = np.where((df_['Do_not_know_(group_1)_M'] == 1) & (df_['Do_not_know_(group_2)_M'] == 1), np.nan, df_['Hip_fracture_M'])\n",
    "df_['Prostate_cancer_M'] = np.where((df_['Do_not_know_(group_1)_M'] == 1) & (df_['Do_not_know_(group_2)_M'] == 1), np.nan, df_['Prostate_cancer_M'])\n",
    "df_['Severe_depression_M'] = np.where((df_['Do_not_know_(group_1)_M'] == 1) & (df_['Do_not_know_(group_2)_M'] == 1), np.nan, df_['Severe_depression_M'])\n",
    "df_['Parkinson_disease_M'] = np.where((df_['Do_not_know_(group_1)_M'] == 1) & (df_['Do_not_know_(group_2)_M'] == 1), np.nan, df_['Parkinson_disease_M'])\n",
    "df_['Alzheimer_disease/dementia_M'] = np.where((df_['Do_not_know_(group_1)_M'] == 1) & (df_['Do_not_know_(group_2)_M'] == 1), np.nan, df_['Alzheimer_disease/dementia_M'])\n",
    "df_['Diabetes_M'] = np.where((df_['Do_not_know_(group_1)_M'] == 1) & (df_['Do_not_know_(group_2)_M'] == 1), np.nan, df_['Diabetes_M'])\n",
    "df_['High_blood_pressure_M'] = np.where((df_['Do_not_know_(group_1)_M'] == 1) & (df_['Do_not_know_(group_2)_M'] == 1), np.nan, df_['High_blood_pressure_M'])\n",
    "df_['Chronic_bronchitis/emphysema_M'] = np.where((df_['Do_not_know_(group_1)_M'] == 1) & (df_['Do_not_know_(group_2)_M'] == 1), np.nan, df_['Chronic_bronchitis/emphysema_M'])\n",
    "df_['Breast_cancer_M'] = np.where((df_['Do_not_know_(group_1)_M'] == 1) & (df_['Do_not_know_(group_2)_M'] == 1), np.nan, df_['Breast_cancer_M'])\n",
    "df_['Bowel_cancer_M'] = np.where((df_['Do_not_know_(group_1)_M'] == 1) & (df_['Do_not_know_(group_2)_M'] == 1), np.nan, df_['Bowel_cancer_M'])\n",
    "df_['Lung_cancer_M'] = np.where((df_['Do_not_know_(group_1)_M'] == 1) & (df_['Do_not_know_(group_2)_M'] == 1), np.nan, df_['Lung_cancer_M'])\n",
    "df_['Stroke_M'] = np.where((df_['Do_not_know_(group_1)_M'] == 1) & (df_['Do_not_know_(group_2)_M'] == 1), np.nan, df_['Stroke_M'])\n",
    "df_['Heart_disease_M'] = np.where((df_['Do_not_know_(group_1)_M'] == 1) & (df_['Do_not_know_(group_2)_M'] == 1), np.nan, df_['Heart_disease_M'])\n",
    "\n",
    "del df_['Illnesses_mother_0']\n",
    "del df_['Illnesses_mother_1']\n",
    "del df_['Illnesses_mother_2']\n",
    "del df_['Illnesses_mother_3']\n",
    "del df_['Illnesses_mother_4']\n",
    "del df_['Illnesses_mother_5']\n",
    "del df_['Illnesses_mother_6']\n",
    "del df_['Illnesses_mother_7']\n",
    "del df_['Illnesses_mother_8']\n",
    "del df_['Illnesses_mother_9']\n",
    "del df_['Illnesses_mother_10']\n",
    "\n",
    "del df_['Do_not_know_(group_1)_M']\n",
    "del df_['Prefer_not_to_answer_(group_1)_M']\n",
    "del df_['None_of_the_above_(group_1)_M']\n",
    "del df_['Do_not_know_(group_2)_M']\n",
    "del df_['Prefer_not_to_answer_(group_2)_M']\n",
    "del df_['None_of_the_above_(group_2)_M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bf4671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your dataframe is named 'df' with the renamed columns\n",
    "# Creating a dictionary to map the code to its corresponding meaning\n",
    "code_meaning = {\n",
    "14:'Hip_fracture_S',\n",
    "13:'Prostate_cancer_S',\n",
    "12:'Severe_depression_S',\n",
    "11:'Parkinson_disease_S',\n",
    "10:'Alzheimer_disease/dementia_S',\n",
    "9:'Diabetes_S',\n",
    "8:'High_blood_pressure_S',\n",
    "6:'Chronic_bronchitis/emphysema_S',\n",
    "5:'Breast_cancer_S',\n",
    "4:'Bowel_cancer_S',\n",
    "3:'Lung_cancer_S',\n",
    "2:'Stroke_S',\n",
    "1:'Heart_disease_S',\n",
    "-11:'Do_not_know_(group_1)_S',\n",
    "-13:'Prefer_not_to_answer_(group_1)_S',\n",
    "-17:'None_of_the_above_(group_1)_S',\n",
    "-21:'Do_not_know_(group_2)_S',\n",
    "-23:'Prefer_not_to_answer_(group_2)_S',\n",
    "-27:'None_of_the_above_(group_2)_S'\n",
    "}\n",
    "\n",
    "# Specify the column names you want to extract\n",
    "columns_to_extract = ['Illnesses_siblings_0', 'Illnesses_siblings_1', 'Illnesses_siblings_2',\n",
    "                      'Illnesses_siblings_3', 'Illnesses_siblings_4', 'Illnesses_siblings_5',\n",
    "                      'Illnesses_siblings_6', 'Illnesses_siblings_7', 'Illnesses_siblings_8',\n",
    "                     'Illnesses_siblings_9', 'Illnesses_siblings_10', 'Illnesses_siblings_11']\n",
    "\n",
    "# Create a new dataframe with only the extracted columns\n",
    "extracted_df = df_[columns_to_extract].copy()\n",
    "\n",
    "# Create a new dataframe to store the results\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over each code and meaning in the dictionary\n",
    "for code, meaning in code_meaning.items():\n",
    "    # Check if the code is positive or negative\n",
    "    is_positive = code > 0\n",
    "\n",
    "    # Create a boolean mask indicating where the code is present in the extracted columns\n",
    "    code_mask = extracted_df.isin([code])\n",
    "\n",
    "    # Count the occurrences of the code in each row\n",
    "    code_counts = code_mask.sum(axis=1)\n",
    "\n",
    "    # Create a new column with the meaning and initialize it as 1 if the code is present, else 0\n",
    "    result_df[meaning] = np.where(code_counts > 0, 1, 0)\n",
    "\n",
    "# Concatenate the result dataframe with the original dataframe\n",
    "df_ = pd.concat([df_, result_df], axis=1)\n",
    "\n",
    "df_['Hip_fracture_S'] = np.where((df_['Prefer_not_to_answer_(group_1)_S'] == 1) & (df_['Prefer_not_to_answer_(group_2)_S'] == 1), np.nan, df_['Hip_fracture_S'])\n",
    "df_['Prostate_cancer_S'] = np.where((df_['Prefer_not_to_answer_(group_1)_S'] == 1) & (df_['Prefer_not_to_answer_(group_2)_S'] == 1), np.nan, df_['Prostate_cancer_S'])\n",
    "df_['Severe_depression_S'] = np.where((df_['Prefer_not_to_answer_(group_1)_S'] == 1) & (df_['Prefer_not_to_answer_(group_2)_S'] == 1), np.nan, df_['Severe_depression_S'])\n",
    "df_['Parkinson_disease_S'] = np.where((df_['Prefer_not_to_answer_(group_1)_S'] == 1) & (df_['Prefer_not_to_answer_(group_2)_S'] == 1), np.nan, df_['Parkinson_disease_S'])\n",
    "df_['Alzheimer_disease/dementia_S'] = np.where((df_['Prefer_not_to_answer_(group_1)_S'] == 1) & (df_['Prefer_not_to_answer_(group_2)_S'] == 1), np.nan, df_['Alzheimer_disease/dementia_S'])\n",
    "df_['Diabetes_S'] = np.where((df_['Prefer_not_to_answer_(group_1)_S'] == 1) & (df_['Prefer_not_to_answer_(group_2)_S'] == 1), np.nan, df_['Diabetes_S'])\n",
    "df_['High_blood_pressure_S'] = np.where((df_['Prefer_not_to_answer_(group_1)_S'] == 1) & (df_['Prefer_not_to_answer_(group_2)_S'] == 1), np.nan, df_['High_blood_pressure_S'])\n",
    "df_['Chronic_bronchitis/emphysema_S'] = np.where((df_['Prefer_not_to_answer_(group_1)_S'] == 1) & (df_['Prefer_not_to_answer_(group_2)_S'] == 1), np.nan, df_['Chronic_bronchitis/emphysema_S'])\n",
    "df_['Breast_cancer_S'] = np.where((df_['Prefer_not_to_answer_(group_1)_S'] == 1) & (df_['Prefer_not_to_answer_(group_2)_S'] == 1), np.nan, df_['Breast_cancer_S'])\n",
    "df_['Bowel_cancer_S'] = np.where((df_['Prefer_not_to_answer_(group_1)_S'] == 1) & (df_['Prefer_not_to_answer_(group_2)_S'] == 1), np.nan, df_['Bowel_cancer_S'])\n",
    "df_['Lung_cancer_S'] = np.where((df_['Prefer_not_to_answer_(group_1)_S'] == 1) & (df_['Prefer_not_to_answer_(group_2)_S'] == 1), np.nan, df_['Lung_cancer_S'])\n",
    "df_['Stroke_S'] = np.where((df_['Prefer_not_to_answer_(group_1)_S'] == 1) & (df_['Prefer_not_to_answer_(group_2)_S'] == 1), np.nan, df_['Stroke_S'])\n",
    "df_['Heart_disease_S'] = np.where((df_['Prefer_not_to_answer_(group_1)_S'] == 1) & (df_['Prefer_not_to_answer_(group_2)_S'] == 1), np.nan, df_['Heart_disease_S'])\n",
    "\n",
    "df_['Hip_fracture_S'] = np.where((df_['Do_not_know_(group_1)_S'] == 1) & (df_['Do_not_know_(group_2)_S'] == 1), np.nan, df_['Hip_fracture_S'])\n",
    "df_['Prostate_cancer_S'] = np.where((df_['Do_not_know_(group_1)_S'] == 1) & (df_['Do_not_know_(group_2)_S'] == 1), np.nan, df_['Prostate_cancer_S'])\n",
    "df_['Severe_depression_S'] = np.where((df_['Do_not_know_(group_1)_S'] == 1) & (df_['Do_not_know_(group_2)_S'] == 1), np.nan, df_['Severe_depression_S'])\n",
    "df_['Parkinson_disease_S'] = np.where((df_['Do_not_know_(group_1)_S'] == 1) & (df_['Do_not_know_(group_2)_S'] == 1), np.nan, df_['Parkinson_disease_S'])\n",
    "df_['Alzheimer_disease/dementia_S'] = np.where((df_['Do_not_know_(group_1)_S'] == 1) & (df_['Do_not_know_(group_2)_S'] == 1), np.nan, df_['Alzheimer_disease/dementia_S'])\n",
    "df_['Diabetes_S'] = np.where((df_['Do_not_know_(group_1)_S'] == 1) & (df_['Do_not_know_(group_2)_S'] == 1), np.nan, df_['Diabetes_S'])\n",
    "df_['High_blood_pressure_S'] = np.where((df_['Do_not_know_(group_1)_S'] == 1) & (df_['Do_not_know_(group_2)_S'] == 1), np.nan, df_['High_blood_pressure_S'])\n",
    "df_['Chronic_bronchitis/emphysema_S'] = np.where((df_['Do_not_know_(group_1)_S'] == 1) & (df_['Do_not_know_(group_2)_S'] == 1), np.nan, df_['Chronic_bronchitis/emphysema_S'])\n",
    "df_['Breast_cancer_S'] = np.where((df_['Do_not_know_(group_1)_S'] == 1) & (df_['Do_not_know_(group_2)_S'] == 1), np.nan, df_['Breast_cancer_S'])\n",
    "df_['Bowel_cancer_S'] = np.where((df_['Do_not_know_(group_1)_S'] == 1) & (df_['Do_not_know_(group_2)_S'] == 1), np.nan, df_['Bowel_cancer_S'])\n",
    "df_['Lung_cancer_S'] = np.where((df_['Do_not_know_(group_1)_S'] == 1) & (df_['Do_not_know_(group_2)_S'] == 1), np.nan, df_['Lung_cancer_S'])\n",
    "df_['Stroke_S'] = np.where((df_['Do_not_know_(group_1)_S'] == 1) & (df_['Do_not_know_(group_2)_S'] == 1), np.nan, df_['Stroke_S'])\n",
    "df_['Heart_disease_S'] = np.where((df_['Do_not_know_(group_1)_S'] == 1) & (df_['Do_not_know_(group_2)_S'] == 1), np.nan, df_['Heart_disease_S'])\n",
    "\n",
    "del df_['Illnesses_siblings_0']\n",
    "del df_['Illnesses_siblings_1']\n",
    "del df_['Illnesses_siblings_2']\n",
    "del df_['Illnesses_siblings_3']\n",
    "del df_['Illnesses_siblings_4']\n",
    "del df_['Illnesses_siblings_5']\n",
    "del df_['Illnesses_siblings_6']\n",
    "del df_['Illnesses_siblings_7']\n",
    "del df_['Illnesses_siblings_8']\n",
    "del df_['Illnesses_siblings_9']\n",
    "del df_['Illnesses_siblings_10']\n",
    "del df_['Illnesses_siblings_11']\n",
    "\n",
    "del df_['Do_not_know_(group_1)_S']\n",
    "del df_['Prefer_not_to_answer_(group_1)_S']\n",
    "del df_['None_of_the_above_(group_1)_S']\n",
    "del df_['Do_not_know_(group_2)_S']\n",
    "del df_['Prefer_not_to_answer_(group_2)_S']\n",
    "del df_['None_of_the_above_(group_2)_S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126ae10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['Standing_height','Fasting_time','Number_cancers',\n",
    "            'Number_operation','Job_walking_standing','Job_heavy_manual',\n",
    "            'Job_involves_shift','Frequency_friend_family_visits',\n",
    "            'Time_outdoors_summer','Time_outdoors_winter','Length_phone_use',\n",
    "            'Weekly_phone_use','Difference_phone_use','Getting_up_in_morning',\n",
    "            'Morning_evening_person','Snoring','Coffee_intake','Skin_colour',\n",
    "            'Mood_swings','Miserableness','Irritability','Sensitivity',\n",
    "            'Fed-up_feelings','Nervous_feelings','Worrier/Anxious_feelings',\n",
    "            'Tense','Worry_too_long_after_embarrassment','Suffer_from_nerves',\n",
    "            'Loneliness_isolation','Guilty_feelings','Risk_taking','Able_to_confide',\n",
    "            'Overall_health_rating','Plays_computer_games','Hearing_difficulty/problems',\n",
    "            'Use_of_sun/uv_protection','Frequency_of_solarium/sunlamp','Had_major_operation',\n",
    "            'Cancer_diagnosed_by_doctor','Fractured/broken_bones','Other_serious_condition',\n",
    "            'Health_satisfaction','Family_relationship satisfaction','Friendships_satisfaction',\n",
    "            'Financial_satisfaction','Ever_manic/hyper','Ever_highly_irritable/argumentative',\n",
    "            'Leg_pain_on_walking','Tinnitus','Length_manic/irritable_episode',\n",
    "            'Severity_of_manic/irritable_episodes','Mean_time_to_identify_matches',\n",
    "            'Bipolar_disorder_status','Weight']\n",
    "\n",
    "for col in variables:\n",
    "    #df_[col] = df_[col].replace([-1,-2,-3,-10,-818],[np.NaN,100,np.NaN,0.5,np.NaN])\n",
    "    df_[col] = df_[col].replace([-1,-2,-3,-10,-121,-818],[np.NaN,999,np.NaN,0.5,np.NaN,np.NaN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d7e25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6f1666",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['Standing_height','Fasting_time','Number_cancers',\n",
    "            'Number_operation','Job_walking_standing','Job_heavy_manual',\n",
    "            'Job_involves_shift','Frequency_friend_family_visits',\n",
    "            'Time_outdoors_summer','Time_outdoors_winter','Length_phone_use',\n",
    "            'Weekly_phone_use','Difference_phone_use','Getting_up_in_morning',\n",
    "            'Morning_evening_person','Snoring','Coffee_intake','Skin_colour',\n",
    "            'Mood_swings','Miserableness','Irritability','Sensitivity',\n",
    "            'Fed-up_feelings','Nervous_feelings','Worrier/Anxious_feelings',\n",
    "            'Tense','Worry_too_long_after_embarrassment','Suffer_from_nerves',\n",
    "            'Loneliness_isolation','Guilty_feelings','Risk_taking','Able_to_confide',\n",
    "            'Overall_health_rating','Plays_computer_games','Hearing_difficulty/problems',\n",
    "            'Use_of_sun/uv_protection','Frequency_of_solarium/sunlamp','Had_major_operation',\n",
    "            'Cancer_diagnosed_by_doctor','Fractured/broken_bones','Other_serious_condition',\n",
    "            'Health_satisfaction','Family_relationship satisfaction','Friendships_satisfaction',\n",
    "            'Financial_satisfaction','Ever_manic/hyper','Ever_highly_irritable/argumentative',\n",
    "            'Leg_pain_on_walking','Tinnitus','Length_manic/irritable_episode',\n",
    "            'Severity_of_manic/irritable_episodes','Mean_time_to_identify_matches',\n",
    "            'Had_other_major_operations',\n",
    "            'Happiness',\n",
    "            'Work/job_satisfaction',\n",
    "            'Cancer_age_first',\n",
    "            'Bipolar_disorder_status','Weight']\n",
    "\n",
    "for col in variables:\n",
    "    #df_[col] = df_[col].replace([-1,-2,-3,-10,-818],[np.NaN,100,np.NaN,0.5,np.NaN])\n",
    "    df_[col] = df_[col].replace([-1,-2,-3,-10,-121,-818],[np.NaN,999,np.NaN,0.5,np.NaN,np.NaN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebebd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_with_negatives = df_.columns[df_.lt(0).any()]; columns_with_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57481ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.to_csv(r'/Users/marinacamacho/Desktop/Master_I/Raw_Data/Time_0/ukb669914_clean.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25335716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca317492",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
